{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X4Fg3TVtcfkK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(22)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(22)"
      ],
      "metadata": {
        "id": "KS3EDMBaciat"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "eXVJQMnLc3fx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(2, 10, bias = True),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(10, 10, bias = True),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(10, 10, bias = True),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(10, 1, bias = True),\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.mlp(x)\n"
      ],
      "metadata": {
        "id": "0INNLPF0c7fL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)"
      ],
      "metadata": {
        "id": "qT9OZDyvdfnn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10001):\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(X)\n",
        "  cost = criterion(hypothesis, Y)\n",
        "\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 ==0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltqjaekdeGmt",
        "outputId": "202c3249-4e12-49f2-9a54-59d5cda0240c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7952476143836975\n",
            "100 0.6931456327438354\n",
            "200 0.6931440234184265\n",
            "300 0.6931424140930176\n",
            "400 0.6931406259536743\n",
            "500 0.6931388974189758\n",
            "600 0.6931370496749878\n",
            "700 0.693135142326355\n",
            "800 0.6931331157684326\n",
            "900 0.6931309103965759\n",
            "1000 0.6931286454200745\n",
            "1100 0.6931260824203491\n",
            "1200 0.6931233406066895\n",
            "1300 0.6931204795837402\n",
            "1400 0.6931172013282776\n",
            "1500 0.6931135654449463\n",
            "1600 0.6931096315383911\n",
            "1700 0.6931051015853882\n",
            "1800 0.693100094795227\n",
            "1900 0.6930943727493286\n",
            "2000 0.6930879354476929\n",
            "2100 0.6930802464485168\n",
            "2200 0.6930714249610901\n",
            "2300 0.6930610537528992\n",
            "2400 0.6930485963821411\n",
            "2500 0.6930336952209473\n",
            "2600 0.6930152177810669\n",
            "2700 0.6929923892021179\n",
            "2800 0.6929634809494019\n",
            "2900 0.6929259300231934\n",
            "3000 0.6928760409355164\n",
            "3100 0.6928077936172485\n",
            "3200 0.6927108764648438\n",
            "3300 0.692566990852356\n",
            "3400 0.6923404932022095\n",
            "3500 0.6919558644294739\n",
            "3600 0.6912292242050171\n",
            "3700 0.6896188259124756\n",
            "3800 0.6849467754364014\n",
            "3900 0.6625417470932007\n",
            "4000 0.5460625290870667\n",
            "4100 0.3654874563217163\n",
            "4200 0.01943947747349739\n",
            "4300 0.007920226082205772\n",
            "4400 0.004762430675327778\n",
            "4500 0.0033409760799258947\n",
            "4600 0.0025465735234320164\n",
            "4700 0.002044199500232935\n",
            "4800 0.0016999791841953993\n",
            "4900 0.001450439915060997\n",
            "5000 0.0012618619948625565\n",
            "5100 0.0011146627366542816\n",
            "5200 0.000996747170574963\n",
            "5300 0.0009003292070701718\n",
            "5400 0.0008201651507988572\n",
            "5500 0.0007524872198700905\n",
            "5600 0.000694626069162041\n",
            "5700 0.0006446859915740788\n",
            "5800 0.000601097708567977\n",
            "5900 0.0005628023063763976\n",
            "6000 0.0005288506508804858\n",
            "6100 0.0004986136918887496\n",
            "6200 0.00047148243174888194\n",
            "6300 0.00044703850289806724\n",
            "6400 0.0004248832701705396\n",
            "6500 0.0004047264519613236\n",
            "6600 0.0003863136225845665\n",
            "6700 0.00036945746978744864\n",
            "6800 0.00035391520941630006\n",
            "6900 0.00033958005951717496\n",
            "7000 0.0003263011749368161\n",
            "7100 0.00031399563886225224\n",
            "7200 0.0003025546611752361\n",
            "7300 0.00029186447500251234\n",
            "7400 0.0002818753710016608\n",
            "7500 0.00027253548614680767\n",
            "7600 0.00026374292792752385\n",
            "7700 0.0002554748789407313\n",
            "7800 0.0002477086381986737\n",
            "7900 0.0002403660473646596\n",
            "8000 0.0002334296004846692\n",
            "8100 0.00022685350268147886\n",
            "8200 0.00022065441589802504\n",
            "8300 0.00021475818357430398\n",
            "8400 0.00020912662148475647\n",
            "8500 0.00020380658679641783\n",
            "8600 0.00019872968550771475\n",
            "8700 0.00019388843793421984\n",
            "8800 0.00018927385099232197\n",
            "8900 0.00018484883185010403\n",
            "9000 0.00018060827278532088\n",
            "9100 0.00017657481657806784\n",
            "9200 0.0001726842747302726\n",
            "9300 0.00016900668560992926\n",
            "9400 0.00016543365200050175\n",
            "9500 0.00016200360551010817\n",
            "9600 0.00015875662211328745\n",
            "9700 0.00015557055303361267\n",
            "9800 0.00015253126912284642\n",
            "9900 0.00014960672706365585\n",
            "10000 0.00014676344289910048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  hypothesis = model(X)\n",
        "  prediction = (hypothesis > 0.5).float()\n",
        "  accuracy = (prediction == Y).float().mean()\n",
        "  print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
        "  print('모델의 예측값(Predicted): ', prediction.detach().cpu().numpy())\n",
        "  print('실제값(Y): ', Y.cpu().numpy())\n",
        "  print('정확도(Accuracy): ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odwCzgXOehIS",
        "outputId": "acab8974-4a46-4df3-de75-59f3cd61de1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 출력값(Hypothesis):  [[1.4037661e-04]\n",
            " [9.9985206e-01]\n",
            " [9.9984848e-01]\n",
            " [1.4712645e-04]]\n",
            "모델의 예측값(Predicted):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "실제값(Y):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy):  1.0\n"
          ]
        }
      ]
    }
  ]
}